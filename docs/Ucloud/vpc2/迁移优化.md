# 迁移优化专项

<p align="right"><font color=Grey>try.chen 2019-10-17</font></p>

> 计划通过该专项优化，完全消除云实例迁移因 flow 下发慢导致的虚拟网络中断(1~2s)。以此使得热迁移对用户完全无感知，极大提升云主机的弹性调度能力和容灾、高可用能力。

---

## 优化背景

### 为什么要做迁移优化

<img title="" src="media/migration-pr-1.png" alt="" data-align="center">

### 现有问题

<img title="" src="media/migration-pr-1.png" alt="" data-align="center">

## 迁移中断原因分析

首先需要明确，目前的机制下为何云实例（如云主机）迁移会导致1-2s 的中断，以此才能对症下药。

### 原因 1：flow重新下发

虚拟网络底层转发依赖 flow。A 和 B 互访，按照是否属于同子网一共需要下发 4~6 条 flow。

以最简单的跨子网访问为例(图 1-1)，vmA 访问 vm时, vmA 和 vm的宿主机 ovs 各需要下发 2 条 flow，分别对应该该流的入向和出向。

<img src="media/migration-1.png" title="" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d8882c8b-a3e3-467e-8a20-7cf9ed6f3a48/Untitled.png" data-align="center">

图1-1

而当 vm 迁移时，如图 1-2 所示，此时该 VPC 内的其他机器（如 vmA）访问 vm 的 flow 会被清理，需要重新下发，而 vm 迁移到 vm‘后，新宿主机上的 flow 也需要下发：

<img src="media/migration-2.png" title="" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3526a833-2002-46c4-b566-fd2cd8673f2e/Untitled.png" data-align="center">

图 1-2

因此，对于vmA 和 vm 正在通信时迁移 vm，*那么一共需要新下发 4 条 flow，此时每条 flow 下发按照 100ms 计算，则共需要耗费 400ms*。

同理，如果VPC 内有 4000 台 vm，那么意味着每台 vm 所在 ovs 都需要新下发 2 条 flow，对于整体通信情况(正在迁移的vm)来说成本是巨大的。

对于 dpdk 网关，如托管云(HCGW)、物理云（VPCGW) 问题还会更糟糕。因为网关的更新周期是一分钟，也就意味着即使云主机已经从宿主机 A 迁移到了 B，但是托管云、物理云网关仍然会将流量送给 A（如图 1-3），**导致最长一分钟的流量中断**。

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/9bd57c3d-a875-491f-a685-613fa58dc92d/Untitled.png](media/migration-3.png)

图 1-3

### 原因 2：端口上报延迟

目前的机制中，当主机迁移完成后会再调用虚拟网络的 `UnlockMigrationIp` 接口，该接口流程较长，其中会同步调用 `UNet3Agent` 的端口上报接口。只有 port 上报完成后，才能执行后续的Flow 下发，而 port 上报这个接口耗时较长。

然而，其实在 vm'在目的宿主机创建时(状态是paused)，目的端的 port 已经被创建(qemu 自动创建)。但此时目的端的 port 无法更新数据库 `t_mac_switch`，因为迁移前调用的 `LockMigrationIp` 接口已经锁定了对应的 mac。

通过对该接口的分析，发现耗时不容乐观：

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e9532779-51c5-4a2b-b58a-2f89da681441/Untitled.png](media/migration-4.png)

图 1-4

其中 P95大部分时刻都超过 1s，甚至达到 2s。

---

## 专项优化

### 优化专项一：relay flow

基本原理如图 2-1 所示：

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/bf21be14-4b3f-4137-8bd9-dc8d904ca03d/Untitled.png](media/migration-5.png)

图 2-1

Relay 机制非常简单，当 vm(宿主机 A)已经迁移到 vm‘(宿主机 B)后，在原先的宿主机A上下发一条relay flow，<mark>将A 收到的是流量转发给 B</mark>。

**这样做得好处是，当整个 VPC 内的 4000 台 vm 有些 flow 未来得及更新，依然将流量送给 A 宿主机时，该部分流量并不会丢弃，而是会被中转给 vm’，之后能被正确处理**。同理，对于延时一分钟更新的VPCGW/HCGW, 也不会导致一分钟的中断，从而带来良好的体验。

Relay 机制的实现同样较为简单，最简单的思路是在 UnlockMigrationIp 接口内部推送一条 idle_timeout=180s 自动过期的 relay flow(需要注意要等 FlowGC处理完)。该 relay flow 中 match 需要匹配tun_id/dst_mac。

Relay flow 支持连续迁移，连续中转。但如果 vm 回迁，则虚拟网络需要感知并清除 relay flow（relay flow 的存在条件是本地不能存在 relay 的目的 mac）。

**重点1**：下发的 relay_flow，timeout 类型为 `idle`，`idle_timeout`=180s。**这样意味着只要 relay_flow 还有流量，relay_flow 就不会过期，就能转发流量**。所以目前的情况下，如果 vmA 正在访问 vm，此时迁移 vm从 A 迁移至 B，迁移完成后，会调用虚拟网络 unlock 接口删除 vmA 上的 flow，使得 vmA更新 flow。如果该 rpc 失败，然后A 上的 vm 又destroy 了，会导致 vmA 访问 vm 不通。而下发 relay flow 后，我们会监控 relay_flow 的时长，如果超过 `idle_timeout`，说明有某个 vm 的 flow 没有被清理，通过告警我们可以及时发现，而后人工处理，同时也不影响 vmA 到 vm 的访问。

<mark><u>通过 relay flow 机制，我们可以解决其中所有源端 flow 下发慢可能带来的中断问题</mark></u>。

**重点 2：** 此外，我们甚至可以将 relay flow 取代为 mirror flow。在vm 迁移进度进入 99%时，在 A 上下发一条镜像 flow，将所有去 vm 的流量镜像一份给 B，这样vm 在 B 上一旦进入 running，立刻就可以接管所有流量。**可以节省 vm 进入 running 到主机调用网络 unlock 成功的一次 rtt。配合后续的改造，理论上支持虚拟网络无损迁移**。

> 因为 vm 从 A 迁到 B 时，理论上状态肯定是一个 paused，一个 running。通过镜像流量，也不会产生 duplicate packet 的问题。通过 mirror，可以将网络的切换时机完全做到和kvm 的切换状态完全一致。

> 开发难度：简单
> 
> 上线难度：简单

### 实现方案

- [x] 确认 vm 回迁
- [x] 确认 vm 原地迁移
- [x] BB 会多送上两个包
- [x] relay flow超时后是否需要 BB 检测
- [x] secondary_ip/vip迁移

`UVPCFE` unlock 时，首先推送 relay flow，通过重试保证成功。

通知`UVPCOps`，`UVPCOps` 持续监控 relay flow 的情况，包括 flow duration，如果超过 180s，说明还有未更新的 src，告警手动处理，直到 relay flow 过期。

目前最高单播优先级 flow 为 60050，因此优先级需要高于 60050。现网发现有 60110 的 flow，因此建议优先级定高为 60200。

如果 vmA和 vm 迁移前宿主机位于同一台宿主机，由于是直接转发，无 tun_id，因此无法匹配到 relay flow。

<img src="media/migration-pr-3.png" title="" alt="" data-align="center">

> - [ ] **剩余未解决问题：**
> 
> - 如果迁移源宿主机上有同VPC其他vm，则下发的relay flow会被flowGC的删flow请求删除，导致relay flow不生效，目前我们依靠重试机制（不可靠）来避免这种问题，但不是最优的解决方案;
> 
> - 同宿主机流量不会被relay flow中转（relay flow中限制了in_port=64200);

### 专项优化二：通过 replace-flow 更新迁移 flow

当前 `FlowGC` 处理迁移时，是简单暴力的将现网相关的 flow 都清理掉了，由 PacketIn 经控制面重新下发flow。当我们回过头来看，精细化运营时，针对迁移引发的 flow 清理，可以通过` replace-flow`来更新 flow，而非删除重下，如图3-1 所示。

<img src="media/migration-6.png" title="" alt="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8a826738-8101-47d6-9a11-22c2a79f92b8/Untitled.png" data-align="center">

图 3-1

> **注意：** replace-flow 匹配不到 flow 时，是否会 insert。

当 vm 迁移时，对于vmA、vmB、vmC 等 vpc 内其他 vm 来说，flow 只有一个字段变化：tun_dst，也即 vm 所在的新宿主机 B。<u>因此如果通过 replace-flow 替换 flow 的话，可以避免flow 的重新下发导致的时延和丢包等</u>。

replace-flow 的优点在于，可以极大地减少迁移过程中的 flow 下发机制，通过直接更新 flow 的 tun_dst 较为简单和直接。

replace-flow 的缺点在于，极端情况下，如果出现 vm 的快速连续迁移，导致并行出现多个 replace-flow 的请求，如果出现乱序则会导致 flow 更新失败，进而导致连通性问题。不过即使这样也没问题，因为每台都会有 relay flow 去中转。

replace-flow 的难点在于，需要 agent 端支持，执行relace-flow前先 针对性的dump-flow，拿到此前的 flow 后再替换 tun_dst并执行 replace-flow 进行替换。

通过 replace-flow 机制，可以避免源端的 flow 重新下发问题。

> 开发难度：中等
> 
> 上线难度：艰难（全网 agent 级别）

### 专项优化三：flow 同步

通过前两个专项，已经可以解决源端下发慢、更新不及时带来的中断问题，但对于迁移的那台 vm 而言，依然存在下发大量 flow 的问题。

对于vm 迁移前后的瞬时状态，其实 flow 是完全一致的（忽略 port 而言）。flow 同步的思路即将 vm在源端宿主机 A 上的所有 flow 同步到目的端宿主机 B 上，并修改相关的信息（主要是 flow 中的 port 信息）。

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c95e6e35-8fb8-4c52-a993-1a728d16ae45/Untitled.png](media/migration-7.png)

图 4-1

> **注意：如果 vm 迁移时，vmC 也发生迁移，则 vmC 的删 flow 请求会发给宿主机 A 或 B，不论发给谁都会出现问题。比如，此时数据库位置为 B，del_flow 发给 B，B 更新后，又被 A 同步过来的 flow 覆盖，导致脏 flow。**

flow 同步的优点是可以避免迁移后的 vm需要下发大量 flow，导致通信被延迟。

flow 同步的缺点是，极端情况下，如果在同步完成后到更新目的端vm位置之间，有 flow 的更新请求发送给宿主机 A，则该请求不会被同步到 B。如果是删除 flow 请求，则会导致宿主机B 上残留有脏 flow。因此对于 flow 同步方案而言，进行同步之前需要保证目的端 port 已经上报，位置已经更新。

> 开发难度：简单
> 
> 上线难度：简单

通过 flow 同步机制，将迁移端的 flow 重新下发也完全避免。通过这三个专项优化已经可以完全解决 flow 下发慢带来的迁移中断，因为全程不需要下发任何 flow（除一条 relay flow 外）。

<img src="media/migration-pr-4.png" title="" alt="" data-align="center">

> - [ ] **剩余未解决问题：**  
> 
> - 如果迁移目的宿主机上有同VPC其他vm，则同步过去的flow会被flowGC的删flow请求删除，导致flow同步不生效，目前我们无法解决这种问题;
> 
> - 同宿主机flow不会被同步；

### 专项优化四：优化 port 上报

目前 port 优化的难点在于，vm 从 A宿主机上迁移到 B 宿主机上的 vm'时：

- 只要 vm'未进入 running 状态，DB 里记录的位置必须是 A；
- 但此时 A 和 B 都在上报，但是 B 的上报会因为唯一索引而被忽略；
- 下发 B 上的 flow 必须依赖 B 的port上报

通过 relay flow 可以避免 port 上报慢带来的问题，详见下文。

### 专项优化五：controller动态刷新flow

由于专项优化二`replace-flow`方案实现较为负责，考虑controller动态刷新flow方案。

由controller提供接口，由控制面调用主动触发controller发起`HandlePacketIn`流程，并下发最新flow。下发flow期间流量会被`Relay-Flow`中转，因此不会有首包时延的问题。当`packet-in`流程完成后，flow会被直接更新，这样源端的flow可以无损更新。

这个方案改动小，风险低，非常轻量级，易于上线。但有一个隐藏问题是，动态触发下发的flow可能会被`unlock`中的删flow请求删除，因此还需要解决这点。

### 调用时序

<img src="media/migration-8.png" title="" alt="" data-align="center">

优化中需要和主机部门配合，将目前 `UnlockMigrationIp` 接口拆分为两个 API。当在目的宿主机上创建迁移vm时(vm 状态是 paused)，调用 `UnlockBegin`（API 名字暂定），`UnlockBegin` 的目的是触发在源目宿主机之间开启周期性 flow 同步（如 1s 一次）。

当目的宿主机vm进入`running` 状态时，调用 `UnlockCommit` 接口。该接口会首先在源端宿主机下发一条高优先级的 flow，拦截所有去往源宿主机的访问 vm 的流量，将其重定向到目的宿主机上。

通过`UnlockBegin`+`UnlockCommit`，保证整个迁移过程中无 flow 下发，同时规避了 port 上报慢的问题，以此时间迁移过程中虚拟网络不中断的效果。

## 迁移优化效果

目前效果统计为flow同步&relay  flow上线的效果：

![](media/migration-pr-5.png)

## 下一步优化方向

- [ ] Relay Flow优化源端删除问题（同宿主机）

- [ ] Flow同步优化目的端删除问题（同宿主机）

- [ ] Controller支持触发刷新flow
